{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Faiss-GPUê°€ Colabì—ì„œ ê°€ì¥ ë¹ ë¦…ë‹ˆë‹¤.\n",
        "!pip install faiss-gpu\n",
        "# FaceNetê³¼ MTCNNì„ í¬í•¨í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install facenet-pytorch\n",
        "# Pillow(PIL) ìµœì‹  ë²„ì „ í™•ì¸\n",
        "!pip install Pillow --upgrade"
      ],
      "metadata": {
        "id": "BQ1enMd3PhS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f98d6d-ba06-43a9-dd31-e18997cc9be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (1.26.4)\n",
            "Collecting Pillow<10.3.0,>=10.2.0 (from facenet-pytorch)\n",
            "  Downloading pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (2.32.4)\n",
            "Collecting torch<2.3.0,>=2.2.0 (from facenet-pytorch)\n",
            "  Downloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision<0.18.0,>=0.17.0 (from facenet-pytorch)\n",
            "  Downloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
            "Downloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.2.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m134.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, facenet-pytorch\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 10.4.0\n",
            "    Uninstalling pillow-10.4.0:\n",
            "      Successfully uninstalled pillow-10.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.20.0 which is incompatible.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.20.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.20.0 which is incompatible.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.2.0 facenet-pytorch-2.6.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (10.2.0)\n",
            "Collecting Pillow\n",
            "  Using cached pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 10.2.0\n",
            "    Uninstalling pillow-10.2.0:\n",
            "      Successfully uninstalled pillow-10.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 12.0.0 which is incompatible.\n",
            "gradio 3.50.2 requires pillow<11.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.20.0 which is incompatible.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.20.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-12.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# ğŸ’¡ ì½”ì‚¬ì¸ ê±°ë¦¬ -> ìœ ì‚¬ë„ í¼ì„¼íŠ¸ ë³€í™˜ ì ìš©ëœ ìµœì¢… ì½”ë“œ\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ìƒˆ ëŸ°íƒ€ì„ì—ì„œ ë‹¤ì‹œ ì„¤ì¹˜ í•„ìš”)\n",
        "!pip install numpy==1.23.5 --quiet\n",
        "!pip install tensorflow opencv-python gradio==3.50.2 pillow scikit-learn --quiet --upgrade\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from scipy.spatial.distance import cosine\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# ğŸš¨ í•œê¸€ ì´ë¦„ ë§¤í•‘ ì‚¬ì „\n",
        "KOREAN_NAMES = {'karina': 'ì¹´ë¦¬ë‚˜', 'winter': 'ìœˆí„°', 'giselle': 'ì§€ì ¤', 'ningning': 'ë‹ë‹'}\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 0. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
        "# ----------------------------------------------------\n",
        "# ì½”ì‚¬ì¸ ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (0% ~ 100%)\n",
        "def distance_to_similarity_percent(distance):\n",
        "    \"\"\"ì½”ì‚¬ì¸ ê±°ë¦¬ë¥¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
        "    # ì½”ì‚¬ì¸ ê±°ë¦¬ (0 ~ 2) -> ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (1 ~ -1) -> ìœ ì‚¬ë„ (0 ~ 2)\n",
        "    # VGG16 ì„ë² ë”©ì€ L2 ì •ê·œí™”ë˜ì–´ ì½”ì‚¬ì¸ ê±°ë¦¬ê°€ 0 ~ 2 ë²”ìœ„ì— ìˆìœ¼ë¯€ë¡œ,\n",
        "    # ìœ ì‚¬ë„(1 - ê±°ë¦¬)ë¥¼ ì‚¬ìš©í•˜ê¸°ë³´ë‹¤ëŠ”, ê±°ë¦¬ê°€ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì ìˆ˜ë¥¼ ì£¼ëŠ” ë°©ì‹ ì‚¬ìš©\n",
        "\n",
        "    # ğŸ’¡ L2 ì •ê·œí™”ëœ VGG16 ì„ë² ë”© ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ê±°ë¦¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 0ì—ì„œ 2 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§‘ë‹ˆë‹¤.\n",
        "    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ = 1 - ì½”ì‚¬ì¸ ê±°ë¦¬ (L2 ì •ê·œí™”ëœ ë²¡í„°ì˜ ê²½ìš° 0 ~ 2 ê±°ë¦¬ì— í•´ë‹¹)\n",
        "\n",
        "    # ì—¬ê¸°ì„œëŠ” ì§ê´€ì ìœ¼ë¡œ 1 - (ê±°ë¦¬/2) * 100% ê³µì‹ì„ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "    # (ê±°ë¦¬ê°€ 0ì¼ ë•Œ 100%, ê±°ë¦¬ê°€ 2ì¼ ë•Œ 0%ì— ê°€ê¹Œì›Œì§€ë„ë¡)\n",
        "\n",
        "    # 1 - (ê±°ë¦¬ / 2) -> 0.0 ~ 1.0 ìŠ¤ì¼€ì¼\n",
        "    similarity = 1 - (distance / 2.0)\n",
        "\n",
        "    # 0% ~ 100% ë³€í™˜\n",
        "    return max(0.0, min(100.0, similarity * 100.0))\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 1. Drive ì—°ê²° ë° Colab ì„ì‹œ ì €ì¥ì†Œ ë³µì‚¬ (íŒŒì¼ ì‹œìŠ¤í…œ ì•ˆì •í™”)\n",
        "# ----------------------------------------------------\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive', force_remount=True)\n",
        "    DRIVE_PHOTO_DIR = Path(\"/content/gdrive/MyDrive/aespa/aespa_photo\")\n",
        "    COLAB_TEMP_DIR = Path(\"/content/temp_aespa_photos\")\n",
        "    COLAB_TEMP_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "    # OSErrors ìš°íšŒë¥¼ ìœ„í•´ Colab ë¡œì»¬ë¡œ ë³µì‚¬\n",
        "    for member_dir in DRIVE_PHOTO_DIR.iterdir():\n",
        "        if member_dir.is_dir():\n",
        "            target_dir = COLAB_TEMP_DIR / member_dir.name\n",
        "            target_dir.mkdir(exist_ok=True)\n",
        "            for img_file in member_dir.glob('*.*'):\n",
        "                shutil.copy(img_file, target_dir)\n",
        "\n",
        "    print(f\"âœ… ì‚¬ì§„ {COLAB_TEMP_DIR} (Colab ë¡œì»¬)ì— ë³µì‚¬ ì™„ë£Œ.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ğŸš¨ Drive ì—°ê²° ë˜ëŠ” ë³µì‚¬ ì‹¤íŒ¨: {e}\")\n",
        "    COLAB_TEMP_DIR = Path(\"/content/gdrive/MyDrive/aespa/aespa_photo\")\n",
        "\n",
        "# íŒŒì¼ ê²½ë¡œ ë° ìƒìˆ˜\n",
        "PHOTO_DIR = COLAB_TEMP_DIR\n",
        "EMBEDDINGS_FILE = Path(\"/content/aespa_embeddings_colab.pkl\")\n",
        "TARGET_SIZE = (224, 224)\n",
        "# ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì„ê³„ê°’ ì¬ì„¤ì • (ê±°ë¦¬ê°€ 0.5ì¼ ë•Œ ìœ ì‚¬ë„ 75% -> 75% ë¯¸ë§Œì´ë©´ ì‹ ë¢°ë„ ë‚®ìŒ)\n",
        "SIMILARITY_THRESHOLD = distance_to_similarity_percent(0.5)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 2. VGG16 ëª¨ë¸ ë¡œë“œ ë° ì„ë² ë”© ë¡œì§ (GPU ì˜¤ë¥˜ ìš°íšŒ ì ìš©)\n",
        "# ----------------------------------------------------\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "with tf.device('/CPU:0'):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3))\n",
        "\n",
        "def create_vgg_embedding_model(model):\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
        "    return Model(inputs=model.input, outputs=x)\n",
        "\n",
        "with tf.device('/CPU:0'):\n",
        "    VGG_EMBEDDING_MODEL = create_vgg_embedding_model(base_model)\n",
        "\n",
        "def preprocess_image(img_path_or_pil):\n",
        "    if isinstance(img_path_or_pil, Path):\n",
        "        img = Image.open(str(img_path_or_pil)).convert('RGB')\n",
        "    else: img = img_path_or_pil.convert('RGB')\n",
        "    img = img.resize(TARGET_SIZE)\n",
        "    img_array = np.array(img).astype('float32')\n",
        "    img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
        "    return np.expand_dims(img_array, axis=0)\n",
        "\n",
        "def get_embedding(model, preprocessed_image_array):\n",
        "    with tf.device('/CPU:0'):\n",
        "        embedding = model.predict(preprocessed_image_array, verbose=0)\n",
        "    embedding = embedding / np.linalg.norm(embedding, axis=1, keepdims=True)\n",
        "    return embedding[0]\n",
        "\n",
        "def create_and_save_embeddings(model, photo_dir, output_file):\n",
        "    if output_file.exists() and output_file.is_file():\n",
        "        try:\n",
        "            with open(output_file, 'rb') as f: return pickle.load(f)\n",
        "        except:\n",
        "            os.remove(output_file)\n",
        "    member_embeddings = {}\n",
        "    if not photo_dir.is_dir(): return {}\n",
        "    for member_name_dir in photo_dir.iterdir():\n",
        "        if member_name_dir.is_dir():\n",
        "            member_name = member_name_dir.name\n",
        "            embeddings = []\n",
        "            photo_paths = []\n",
        "            for img_path in member_name_dir.glob('*.*'):\n",
        "                try:\n",
        "                    preprocessed_img = preprocess_image(img_path)\n",
        "                    embedding = get_embedding(model, preprocessed_img)\n",
        "                    embeddings.append(embedding)\n",
        "                    photo_paths.append(str(img_path))\n",
        "                except: pass\n",
        "            if embeddings:\n",
        "                member_embeddings[member_name] = {\"embeddings\": np.array(embeddings), \"photo_paths\": photo_paths}\n",
        "    if member_embeddings:\n",
        "        with open(output_file, 'wb') as f: pickle.dump(member_embeddings, f)\n",
        "        return member_embeddings\n",
        "    return {}\n",
        "\n",
        "# --- ë©”ì¸ ë°ì´í„° ë¡œë“œ ---\n",
        "MEMBER_EMBEDDINGS_DATA = create_and_save_embeddings(VGG_EMBEDDING_MODEL, PHOTO_DIR, EMBEDDINGS_FILE)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 4. Gradio ë¶„ì„ í•¨ìˆ˜ (ìœ ì‚¬ë„ í¼ì„¼íŠ¸ ì¶œë ¥)\n",
        "# ----------------------------------------------------\n",
        "def analyze_similarity(image_pil):\n",
        "    if image_pil is None or not MEMBER_EMBEDDINGS_DATA:\n",
        "        return \"âš ï¸ ì˜¤ë¥˜: ì´ˆê¸°í™” ë˜ëŠ” ì‚¬ì§„ ì—…ë¡œë“œ ì‹¤íŒ¨.\", None\n",
        "\n",
        "    try:\n",
        "        user_preprocessed = preprocess_image(image_pil)\n",
        "        user_embedding = get_embedding(VGG_EMBEDDING_MODEL, user_preprocessed)\n",
        "    except Exception as e:\n",
        "        return f\"âŒ ì‚¬ìš©ì ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: ì´ë¯¸ì§€ íŒŒì¼ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ({e})\", None\n",
        "\n",
        "    # ëª¨ë“  ë©¤ë²„ì˜ ìµœì†Œ ìœ ì‚¬ë„ ì •ë³´ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
        "    all_max_similarities = {}\n",
        "    best_match = {\"member\": \"ë¯¸ì •\", \"distance\": 1.0, \"photo_path\": None}\n",
        "\n",
        "    for member_name, data in MEMBER_EMBEDDINGS_DATA.items():\n",
        "        member_embeddings = data[\"embeddings\"]\n",
        "\n",
        "        distances = [cosine(emb, user_embedding) for emb in member_embeddings]\n",
        "        min_dist = np.min(distances)\n",
        "        min_dist_index = np.argmin(distances)\n",
        "\n",
        "        # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ %ë¡œ ë³€í™˜\n",
        "        max_similarity_percent = distance_to_similarity_percent(min_dist)\n",
        "        all_max_similarities[member_name] = max_similarity_percent\n",
        "\n",
        "        # ê°€ì¥ ê±°ë¦¬ê°€ ê°€ê¹Œìš´ (ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€) ë©¤ë²„ ì°¾ê¸°\n",
        "        if min_dist < best_match[\"distance\"]:\n",
        "            min_dist_photo_path = data[\"photo_paths\"][min_dist_index]\n",
        "            best_match.update({\n",
        "                \"member\": member_name,\n",
        "                \"distance\": min_dist, # ê±°ë¦¬ëŠ” ë‚´ë¶€ ê³„ì‚°ìš©ìœ¼ë¡œ ìœ ì§€\n",
        "                \"photo_path\": min_dist_photo_path\n",
        "            })\n",
        "\n",
        "    final_output_markdown = \"\"\n",
        "    best_member_name = best_match[\"member\"]\n",
        "    best_member_korean = KOREAN_NAMES.get(best_member_name, best_member_name)\n",
        "\n",
        "    matched_photo_path = best_match[\"photo_path\"]\n",
        "    best_similarity = all_max_similarities[best_member_name]\n",
        "\n",
        "    confidence_warning = \"\"\n",
        "    # ìœ ì‚¬ë„ ì„ê³„ê°’(75%)ë³´ë‹¤ ë‚®ìœ¼ë©´ ì‹ ë¢°ë„ ê²½ê³  í‘œì‹œ\n",
        "    if best_similarity < SIMILARITY_THRESHOLD:\n",
        "        confidence_warning = f\"\\nâš ï¸ **ì£¼ì˜:** ë¶„ì„ ê²°ê³¼ì˜ ì‹ ë¢°ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ìœ ì‚¬ë„: {best_similarity:.2f}%)\"\n",
        "    else:\n",
        "        # ìµœê³  ìœ ì‚¬ë„ ê°’ì„ ì§ì ‘ ì¶œë ¥ ë©”ì‹œì§€ì— í¬í•¨\n",
        "        confidence_warning = f\"\\nâœ… **ìµœê³  ìœ ì‚¬ë„:** {best_similarity:.2f}%\"\n",
        "\n",
        "\n",
        "    # 1. ìµœìƒë‹¨ ê°„ê²° ë©”ì‹œì§€ ì¶œë ¥ (ìœ ì‚¬ë„ í¼ì„¼íŠ¸ í¬í•¨)\n",
        "    final_output_markdown += f\"## ì œì¼ ë‹®ì€ ì‚¬ëŒì€ **{best_member_korean}** ì…ë‹ˆë‹¤.\"\n",
        "    final_output_markdown += confidence_warning\n",
        "    final_output_markdown += \"\\nê°€ì¥ ìœ ì‚¬í•œ ì‚¬ì§„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\\n\"\n",
        "\n",
        "    # 2. ğŸ’¡ ìœ ì‚¬ë„ í¼ì„¼íŠ¸ ê¸°ë°˜ ë¶„ì„ í‘œ ì¶”ê°€\n",
        "    final_output_markdown += \"\\n### ğŸ“Š ë©¤ë²„ë³„ ìµœëŒ€ ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼\\n\"\n",
        "    final_output_markdown += \"| ë©¤ë²„ | ìµœëŒ€ ìœ ì‚¬ë„ (%) (â†‘) |\\n\" # ìœ ì‚¬ë„ëŠ” ë†’ì„ìˆ˜ë¡ ë‹®ìŒ (â†‘ í‘œì‹œ)\n",
        "    final_output_markdown += \"|---|---|\\n\"\n",
        "\n",
        "    # ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬\n",
        "    sorted_similarities = sorted(all_max_similarities.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    for member_name, sim_percent in sorted_similarities:\n",
        "        member_name_korean = KOREAN_NAMES.get(member_name, member_name)\n",
        "        # ê°€ì¥ ë‹®ì€ ë©¤ë²„ëŠ” êµµê²Œ í‘œì‹œ\n",
        "        if member_name == best_member_name:\n",
        "             final_output_markdown += f\"| **{member_name_korean}** | **{sim_percent:.2f}%** |\\n\"\n",
        "        else:\n",
        "             final_output_markdown += f\"| {member_name_korean} | {sim_percent:.2f}% |\\n\"\n",
        "\n",
        "    final_output_markdown += \"\\n* \"\n",
        "\n",
        "\n",
        "    return final_output_markdown, matched_photo_path\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 5. Gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰ (ì¶œë ¥ í•­ëª© ë³€ê²½ ì—†ìŒ)\n",
        "# ----------------------------------------------------\n",
        "if MEMBER_EMBEDDINGS_DATA:\n",
        "    print(\"\\n\\nğŸ‰ğŸ‰ ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ! Gradio ì•± ì‹¤í–‰ ì¤‘...\")\n",
        "\n",
        "    original_cwd = os.getcwd()\n",
        "    os.chdir('/content')\n",
        "    print(\"DEBUG: ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ /contentë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "    iface = gr.Interface(\n",
        "        fn=analyze_similarity,\n",
        "        inputs=gr.Image(type=\"pil\", label=\"ğŸ“¸ ë¶„ì„í•  ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”\"),\n",
        "        outputs=[\n",
        "            gr.Markdown(label=\"ë¶„ì„ ê²°ê³¼\"),\n",
        "            # ì‚¬ì§„ í¬ê¸° í™•ëŒ€ (300x300)\n",
        "            gr.Image(label=\"ê°€ì¥ ë‹®ì€ ë©¤ë²„ (ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ì§„)\", type=\"filepath\", width=300, height=300)\n",
        "        ],\n",
        "        # Gradio ì œëª© ë³€ê²½\n",
        "        title=\"ì—ìŠ¤íŒŒ ë‹®ì€ ê¼´ ì°¾ê¸°\",\n",
        "        description=\"ê°€ì¥ ë‹®ì€ ì—ìŠ¤íŒŒ ë©¤ë²„ë¥¼ ì°¾ì•„ ë“œë¦½ë‹ˆë‹¤.\",\n",
        "        theme=gr.themes.Soft()\n",
        "    )\n",
        "\n",
        "    print(\"\\n\\nğŸš€ Gradio ì•± ì‹¤í–‰ ì¤‘... ê³µê°œ ë§í¬(Public URL)ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "    iface.launch(share=True, debug=False, show_error=True)\n",
        "\n",
        "    os.chdir(original_cwd)\n",
        "\n",
        "else:\n",
        "    print(\"\\n\\nğŸš¨ğŸš¨ Gradio ì•± ì‹¤í–‰ ì‹¤íŒ¨. ëŸ°íƒ€ì„ ë° Colab ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZOw6C60ekph8",
        "outputId": "90dce41d-a68b-4fc7-a2e2-4a2a13b7f1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Mounted at /content/gdrive\n",
            "âœ… ì‚¬ì§„ /content/temp_aespa_photos (Colab ë¡œì»¬)ì— ë³µì‚¬ ì™„ë£Œ.\n",
            "\n",
            "\n",
            "ğŸ‰ğŸ‰ ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ! Gradio ì•± ì‹¤í–‰ ì¤‘...\n",
            "DEBUG: ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ /contentë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "\n",
            "ğŸš€ Gradio ì•± ì‹¤í–‰ ì¤‘... ê³µê°œ ë§í¬(Public URL)ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://07cfd1f211b229ed8b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://07cfd1f211b229ed8b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "-"
      ],
      "metadata": {
        "id": "SN2KYjtpmaV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SyiycfUYIZb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-k4RSiROEeL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}